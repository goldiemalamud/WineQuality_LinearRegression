{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import KFold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Implement a function that takes in the *train.csv* dataset and returns a cleaned dataset without outliers and NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.76</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.066</td>\n",
       "      <td>7.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.00040</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.60</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.063</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.99608</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.116</td>\n",
       "      <td>26.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.99722</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.9</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.098</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.00040</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.61</td>\n",
       "      <td>10.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           12.0              0.37         0.76             4.2      0.066   \n",
       "1            7.1              0.69         0.08             2.1      0.063   \n",
       "2            9.6              0.50         0.36             2.8      0.116   \n",
       "3            7.7              0.96         0.20             2.0      0.047   \n",
       "5           11.9              0.38         0.49             2.7      0.098   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                  7.0                  38.0  1.00040  3.22       0.60   \n",
       "1                 42.0                  52.0  0.99608  3.42       0.60   \n",
       "2                 26.0                  55.0  0.99722  3.18       0.68   \n",
       "3                 15.0                  60.0  0.99550  3.36       0.44   \n",
       "5                 12.0                  42.0  1.00040  3.16       0.61   \n",
       "\n",
       "   alcohol  quality  \n",
       "0     13.0        7  \n",
       "1     10.2        6  \n",
       "2     10.9        5  \n",
       "3     10.9        5  \n",
       "5     10.3        5  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "def preprocessing_pipeline(train):\n",
    "    ## Your code goes here\n",
    "    train = train.dropna() #removes all NAs\n",
    "    train = train.drop(columns=['Id'], axis=1) #remove ID column, unnecessay \n",
    "    \n",
    "    #remove outliers\n",
    "    for column in train:\n",
    "        \n",
    "        # Calculate the mean and standard deviation\n",
    "        mu = np.mean(train[column])\n",
    "        std = np.std(train[column])\n",
    "\n",
    "        # Normalize the data\n",
    "        normalized_data = (train[column] - mu)/std\n",
    "\n",
    "        # Find the data index that is 3 standard deviation away from the distribution\n",
    "        indexes = normalized_data < 3\n",
    "        train = train.loc[indexes, :]\n",
    "        processed_train = train\n",
    "    \n",
    "    return processed_train\n",
    "train_clean = preprocessing_pipeline(train)\n",
    "train_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Implement a function that takes in the R<sup>2</sup> of a regression and return the VIF value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(r_squared):\n",
    "    ## Your code goes here\n",
    "    vif = 1/(1-r_squared)\n",
    "    \n",
    "    return vif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Implement a function that takes in preprocessed data and returns a dataframe that contains the VIF for each variable. The dataframe should contain two columns: variable names and their VIFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vif_dataframe(processed_train):\n",
    "    ## Your code goes here\n",
    "    newData = []\n",
    "    columnArray = []\n",
    "\n",
    "    vif_train = processed_train.drop(['quality'], axis = 1)\n",
    "    columns = vif_train.columns\n",
    "    \n",
    "    for col in columns:\n",
    "        \n",
    "        columnArray = [col]\n",
    "        X = vif_train.drop(col,axis=1).values\n",
    "        y = vif_train[col].values\n",
    "        \n",
    "        #calculate regression\n",
    "        heights_constant_added = sm.add_constant(X)\n",
    "        results = sm.OLS(y, heights_constant_added).fit()\n",
    "        r2 = results.rsquared\n",
    "        \n",
    "        vif = round(calculate_vif(r2), 3)\n",
    "        columnArray.append(vif)\n",
    "        newData.append(columnArray)\n",
    "        \n",
    "        vif_dataframe = pd.DataFrame(newData, columns = ['Variable', 'VIF'])   \n",
    "    \n",
    "    \n",
    "    return vif_dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Use the functions that you developed from Q1 and generate a VIF dataframe for all the variables in the wine dataset. Discuss the VIF values you find and the effect of multicollinearity on regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed acidity</td>\n",
       "      <td>7.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>volatile acidity</td>\n",
       "      <td>1.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>citric acid</td>\n",
       "      <td>3.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>residual sugar</td>\n",
       "      <td>1.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chlorides</td>\n",
       "      <td>1.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>free sulfur dioxide</td>\n",
       "      <td>1.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total sulfur dioxide</td>\n",
       "      <td>2.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>density</td>\n",
       "      <td>6.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pH</td>\n",
       "      <td>3.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sulphates</td>\n",
       "      <td>1.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>2.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Variable    VIF\n",
       "0          fixed acidity  7.884\n",
       "1       volatile acidity  1.875\n",
       "2            citric acid  3.209\n",
       "3         residual sugar  1.651\n",
       "4              chlorides  1.183\n",
       "5    free sulfur dioxide  1.976\n",
       "6   total sulfur dioxide  2.204\n",
       "7                density  6.251\n",
       "8                     pH  3.231\n",
       "9              sulphates  1.253\n",
       "10               alcohol  2.992"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code goes here\n",
    "generate_vif_dataframe(train_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your discussion goes here\n",
    "\n",
    "#There are 2 variables where their VIF is > 5, this means that multicollinearity is present in my model. Fixed Acidity has a VIF\n",
    "#of 7.884 and Density has a VIF of 6.251. Multicollinearity means that 2 or more predictor variables are highly correlated.\n",
    "#This is typically bad because it effects our judgement as to which variables are important to our overall model. \n",
    "#Multicollinearity also means that there is weak support for our regression plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Use the VIF dataframe you generated from Q1 and choose a subset of variables that does not have high multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here\n",
    "\n",
    "#subset of variables that do not have high multicollinearity i.e. VIF < 5 (took out fixed acidity and density)\n",
    "\n",
    "X = train_clean[[\"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\",\"pH\", \"sulphates\",\"alcohol\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Fit a multiple linear regression model and print a summary of the regression result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   68.45</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 16 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>1.03e-97</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:41:38</td>     <th>  Log-Likelihood:    </th> <td> -945.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   995</td>      <th>  AIC:               </th> <td>   1910.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   985</td>      <th>  BIC:               </th> <td>   1959.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    4.2764</td> <td>    0.613</td> <td>    6.980</td> <td> 0.000</td> <td>    3.074</td> <td>    5.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -1.0243</td> <td>    0.153</td> <td>   -6.682</td> <td> 0.000</td> <td>   -1.325</td> <td>   -0.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>   -0.3771</td> <td>    0.157</td> <td>   -2.397</td> <td> 0.017</td> <td>   -0.686</td> <td>   -0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.0088</td> <td>    0.024</td> <td>    0.363</td> <td> 0.717</td> <td>   -0.039</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -2.5190</td> <td>    0.999</td> <td>   -2.521</td> <td> 0.012</td> <td>   -4.479</td> <td>   -0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0040</td> <td>    0.003</td> <td>    1.318</td> <td> 0.188</td> <td>   -0.002</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0026</td> <td>    0.001</td> <td>   -2.536</td> <td> 0.011</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>   -0.6287</td> <td>    0.173</td> <td>   -3.642</td> <td> 0.000</td> <td>   -0.967</td> <td>   -0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    1.4980</td> <td>    0.173</td> <td>    8.683</td> <td> 0.000</td> <td>    1.159</td> <td>    1.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.3245</td> <td>    0.023</td> <td>   14.287</td> <td> 0.000</td> <td>    0.280</td> <td>    0.369</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.378</td> <th>  Durbin-Watson:     </th> <td>   2.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.041</td> <th>  Jarque-Bera (JB):  </th> <td>   8.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.003</td> <th>  Prob(JB):          </th> <td>  0.0152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.449</td> <th>  Cond. No.          </th> <td>2.77e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.77e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.385\n",
       "Model:                            OLS   Adj. R-squared:                  0.379\n",
       "Method:                 Least Squares   F-statistic:                     68.45\n",
       "Date:                Sun, 16 Feb 2020   Prob (F-statistic):           1.03e-97\n",
       "Time:                        23:41:38   Log-Likelihood:                -945.07\n",
       "No. Observations:                 995   AIC:                             1910.\n",
       "Df Residuals:                     985   BIC:                             1959.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    4.2764      0.613      6.980      0.000       3.074       5.479\n",
       "volatile acidity        -1.0243      0.153     -6.682      0.000      -1.325      -0.723\n",
       "citric acid             -0.3771      0.157     -2.397      0.017      -0.686      -0.068\n",
       "residual sugar           0.0088      0.024      0.363      0.717      -0.039       0.056\n",
       "chlorides               -2.5190      0.999     -2.521      0.012      -4.479      -0.559\n",
       "free sulfur dioxide      0.0040      0.003      1.318      0.188      -0.002       0.010\n",
       "total sulfur dioxide    -0.0026      0.001     -2.536      0.011      -0.005      -0.001\n",
       "pH                      -0.6287      0.173     -3.642      0.000      -0.967      -0.290\n",
       "sulphates                1.4980      0.173      8.683      0.000       1.159       1.837\n",
       "alcohol                  0.3245      0.023     14.287      0.000       0.280       0.369\n",
       "==============================================================================\n",
       "Omnibus:                        6.378   Durbin-Watson:                   2.073\n",
       "Prob(Omnibus):                  0.041   Jarque-Bera (JB):                8.372\n",
       "Skew:                          -0.003   Prob(JB):                       0.0152\n",
       "Kurtosis:                       3.449   Cond. No.                     2.77e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.77e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code goes here\n",
    "y=train_clean[\"quality\"]\n",
    "\n",
    "results = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Use 5-fold cross validation to validate the mean squared error (MSE) of a multiple linear regression model fit to the subset of data. (HINT: You will need to implement a function to calculate the MSE. See this link for more details: https://en.wikipedia.org/wiki/Mean_squared_error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MSE is: 0.4021195039657126\n"
     ]
    }
   ],
   "source": [
    "## Your code goes here\n",
    "# kfold function will split the data \"x\" into \"k\" equal-sized data sets\n",
    "def kfold(X,k):\n",
    "    i = 0 \n",
    "    while i < k:\n",
    "        xtrain = np.split(X,k)\n",
    "        return xtrain\n",
    "        i += 1\n",
    "\n",
    "# linreg function performs a multi-linear regression thru the x data sets & return the coefficients\n",
    "def linreg(X,y):\n",
    "    s = sm.add_constant(X)\n",
    "    r = sm.OLS(y,s).fit()\n",
    "    return r.params\n",
    "\n",
    "# Calculating yhat = constant + b1*x1 + b2*x2 + b3*x3 + b4*x4 + b5*x5 +b6*x6 +b7*x7 + b8*x8 + b9*x9\n",
    "def yhat(parameters,X):\n",
    "    yhat = parameters[0] + parameters[1]*X.iloc[:,0] + parameters[2]*X.iloc[:,1] + parameters[3]*X.iloc[:,2] + parameters[4]*X.iloc[:,3] + parameters[5]*X.iloc[:,4] + parameters[6]*X.iloc[:,5] + parameters[7]*X.iloc[:,6] + parameters[8]*X.iloc[:,7]+parameters[9]*X.iloc[:,8]\n",
    "    return yhat\n",
    "\n",
    "#Calculating MSE \n",
    "def mse(yi,yhat):\n",
    "    n = len(yi)\n",
    "    mse_score = (1/n) * np.sum((yi - yhat)**2)\n",
    "    return mse_score\n",
    "      \n",
    "t1,t2,t3,t4,t5 = kfold(X,5)\n",
    "q1,q2,q3,q4,q5 = kfold(y,5)\n",
    "\n",
    "\n",
    "# Implementing 5-fold cross validation\n",
    "\n",
    "#Round 1: 5th fold = test set\n",
    "xtrain = [t1,t2,t3,t4]\n",
    "ytrain = [q1,q2,q3,q4]\n",
    "xtrain_set = pd.concat(xtrain) \n",
    "ytrain_set = pd.concat(ytrain)\n",
    "p = linreg(xtrain_set,ytrain_set)\n",
    "\n",
    "yhat_train = yhat(p,t5)\n",
    "mse1 = mse(q5,yhat_train)\n",
    "\n",
    "#Round 2: 4th fold = test set\n",
    "xtrain = [t1,t2,t3,t5]\n",
    "ytrain = [q1,q2,q3,q5]\n",
    "xtrain_set = pd.concat(xtrain) \n",
    "ytrain_set = pd.concat(ytrain)\n",
    "p = linreg(xtrain_set,ytrain_set)\n",
    "\n",
    "yhat_train = yhat(p,t4)\n",
    "mse2 = mse(q4,yhat_train)\n",
    "\n",
    "#Round 3: 3rd fold = test set\n",
    "xtrain = [t1,t2,t4,t5]\n",
    "ytrain = [q1,q2,q4,q5]\n",
    "xtrain_set = pd.concat(xtrain) \n",
    "ytrain_set = pd.concat(ytrain)\n",
    "p = linreg(xtrain_set,ytrain_set)\n",
    "\n",
    "yhat_train = yhat(p,t3)\n",
    "mse3 = mse(q3,yhat_train)\n",
    "\n",
    "#Round 4: 2nd fold = test set\n",
    "xtrain = [t1,t3,t4,t5]\n",
    "ytrain = [q1,q3,q4,q5]\n",
    "xtrain_set = pd.concat(xtrain) \n",
    "ytrain_set = pd.concat(ytrain)\n",
    "p = linreg(xtrain_set,ytrain_set)\n",
    "\n",
    "yhat_train = yhat(p,t2)\n",
    "mse4 = mse(q2,yhat_train)\n",
    "\n",
    "#Round 5: 1st fold = test set\n",
    "xtrain = [t2,t3,t4,t5]\n",
    "ytrain = [q2,q3,q4,q5]\n",
    "xtrain_set = pd.concat(xtrain) \n",
    "ytrain_set = pd.concat(ytrain)\n",
    "p = linreg(xtrain_set,ytrain_set)\n",
    "\n",
    "yhat_train = yhat(p,t1)\n",
    "mse5 = mse(q1,yhat_train)\n",
    "\n",
    "average_mse = (mse1 + mse2 + mse3 + mse4 + mse5)/5\n",
    "\n",
    "\n",
    "\n",
    "# Calculating the MSE between the actual quality given & the estimated quality from multi-linear regression\n",
    "print(\"The average MSE is:\",average_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Make a prediction on the test set using the model you fit in 2b and submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "x2test = test[[\"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\",\"pH\", \"sulphates\",\"alcohol\"]]\n",
    "\n",
    "x2train = train_clean[[\"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\",\"pH\", \"sulphates\",\"alcohol\"]]\n",
    "quality = train_clean['quality']\n",
    "\n",
    "new_para = linreg(x2train,quality)\n",
    "pred = yhat(new_para,x2test)\n",
    "\n",
    "test['predicted'] = pred\n",
    "\n",
    "#submit to kaggle\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Create a dummy submission that has entries as many as the test set.\n",
    "y_pred = np.random.rand(test.shape[0]) * 10 # Create random numbers from 0-10 as dummy solution\n",
    "sample_submission.loc[:, 'Predicted'] = pred # Change the Predicted column to your prediction\n",
    "sample_submission.head()\n",
    "sample_submission.to_csv('Goldie_Malamud_HW2(1).csv', header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Compare the Kaggle score and the cross-validation result. Is the cross-validation result a good representation of the prediction accuracy on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your discussion here\n",
    "'''\n",
    "Kaggle Score = 0.47871\n",
    "cross-validation MSE = 0.40211\n",
    "\n",
    "Yes, I believe that the cross-validation result is a good representation of the prediction accuaracy on the test data. \n",
    "As you can see, the kaggle score and the MSE and only 0.07 apart.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Discuss the difference between goodness of fit on the training set, on the validation set, and on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your discussion here\n",
    "'''\n",
    "Goodness of fit on the training set means how \"well\"/how much of the variance of the training set is captured in the model created.\n",
    "Whereas goodness of fit on the validation set refers to how well your model has been trained. And finally, goodness of fit\n",
    "on the test set refers to how well the model can be applied to \"future data\" or \"real-world data\" and comparing with the outcomes\n",
    "when they occur. \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
