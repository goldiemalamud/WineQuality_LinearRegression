{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 Multiple Linear Regression (4 points)\n",
    "a. Read in train.csv, remove all outliers and missing values (you can refer back to the solution of of HW1 posted on Canvas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#read in train.csv\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train.head()\n",
    "\n",
    "#remove all missing values\n",
    "\n",
    "train = train.dropna() # Let's just get rid of the NAs.\n",
    "train.shape\n",
    "\n",
    "#remove outliers\n",
    "\n",
    "def remove_outliers(data):\n",
    "    \n",
    "    for column in data:\n",
    "        \n",
    "        # Calculate the mean and standard deviation\n",
    "        mu = np.mean(data[column])\n",
    "        std = np.std(data[column])\n",
    "\n",
    "        # Normalize the data\n",
    "        normalized_data = (data[column] - mu)/std\n",
    "\n",
    "        # Find the data index that is 3 standard deviation away from the distribution\n",
    "        indexes = normalized_data < 3\n",
    "        data = data.loc[indexes, :]\n",
    "    return data\n",
    "    \n",
    "train = remove_outliers(train) #cleaned data set\n",
    "#train.shape #cleaned data from outliers & missing values \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Fit a single linear regression model on variable 'citric acid' using the Statsmodels package, print the summary of the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.048\n",
      "Model:                            OLS   Adj. R-squared:                  0.047\n",
      "Method:                 Least Squares   F-statistic:                     49.90\n",
      "Date:                Wed, 12 Feb 2020   Prob (F-statistic):           3.05e-12\n",
      "Time:                        15:53:55   Log-Likelihood:                -1162.4\n",
      "No. Observations:                 995   AIC:                             2329.\n",
      "Df Residuals:                     993   BIC:                             2339.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.4065      0.042    128.102      0.000       5.324       5.489\n",
      "x1             0.9123      0.129      7.064      0.000       0.659       1.166\n",
      "==============================================================================\n",
      "Omnibus:                        9.116   Durbin-Watson:                   1.946\n",
      "Prob(Omnibus):                  0.010   Jarque-Bera (JB):                9.073\n",
      "Skew:                           0.228   Prob(JB):                       0.0107\n",
      "Kurtosis:                       3.107   Cond. No.                         5.61\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "## Your code goes here\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def statsmodel(X, Y):\n",
    "    \n",
    "    heights_constant_added = sm.add_constant(X)\n",
    "    results = sm.OLS(Y, heights_constant_added).fit()\n",
    "    print(results.summary())\n",
    "\n",
    "X_citricAcid = train['citric acid'].values\n",
    "Y = train['quality'].values\n",
    "\n",
    "statsmodel(X_citricAcid,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Fit a single linear regression model on variable 'sulphates' using the Statsmodels package, print the summary of the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.134\n",
      "Model:                            OLS   Adj. R-squared:                  0.133\n",
      "Method:                 Least Squares   F-statistic:                     153.6\n",
      "Date:                Wed, 12 Feb 2020   Prob (F-statistic):           6.69e-33\n",
      "Time:                        15:53:58   Log-Likelihood:                -1115.2\n",
      "No. Observations:                 995   AIC:                             2234.\n",
      "Df Residuals:                     993   BIC:                             2244.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.1601      0.122     33.998      0.000       3.920       4.400\n",
      "x1             2.3259      0.188     12.393      0.000       1.958       2.694\n",
      "==============================================================================\n",
      "Omnibus:                       10.017   Durbin-Watson:                   1.978\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):               11.836\n",
      "Skew:                           0.153   Prob(JB):                      0.00269\n",
      "Kurtosis:                       3.438   Cond. No.                         11.3\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "## Your code goes here\n",
    "X_sulphates = train['sulphates'].values\n",
    "\n",
    "statsmodel(X_sulphates,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Fit a multiple linear regression model on 'citric acid' and 'sulphates' together using the Statsmodels package, print the summary of the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.149\n",
      "Model:                            OLS   Adj. R-squared:                  0.147\n",
      "Method:                 Least Squares   F-statistic:                     86.85\n",
      "Date:                Wed, 12 Feb 2020   Prob (F-statistic):           1.75e-35\n",
      "Time:                        16:01:07   Log-Likelihood:                -1106.5\n",
      "No. Observations:                 995   AIC:                             2219.\n",
      "Df Residuals:                     992   BIC:                             2234.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           4.1619      0.121     34.295      0.000       3.924       4.400\n",
      "citric acid     0.5323      0.127      4.189      0.000       0.283       0.782\n",
      "sulphates       2.1026      0.194     10.860      0.000       1.723       2.483\n",
      "==============================================================================\n",
      "Omnibus:                        6.647   Durbin-Watson:                   1.989\n",
      "Prob(Omnibus):                  0.036   Jarque-Bera (JB):                7.207\n",
      "Skew:                           0.132   Prob(JB):                       0.0272\n",
      "Kurtosis:                       3.323   Cond. No.                         11.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "## Your code goes here\n",
    "X_citric_sulphates = train[['citric acid','sulphates']]\n",
    "statsmodel(X_citric_sulphates,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Compare the goodness of fit of the three models you have from b, c, and d. Which one do you think is a better fit for the data you have? Explain your answer using the R<sup>2</sup>, adj-R<sup>2</sup>, AIC, and BIC, if necessarry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your discussion goes here\n",
    "'''\n",
    "Notes: \n",
    "adj-R^2: penalizes models for having more variables if those additional variables do not reduce the overall \n",
    "         residual sum of squares (RSS)\n",
    "\n",
    "AIC: Generally, a lower AIC indicates a better model fit.\n",
    "BIC: AIC results should be preferred over BIC, lower BIC indicates better fit model \n",
    "\n",
    "#b) R^2 = 0.048, adj-R^2 = 0.047, AIC = 2329, BIC = 2339\n",
    "#c) R^2 = 0.134, adj-R^2 = 0.133, AIC = 2234, BIC = 2244\n",
    "#d) R^2 = 0.149, adj-R^2 = 0.147, AIC = 2219, BIC = 2234 \n",
    "'''\n",
    "\n",
    "#I believe that the multiple linear regression model found in part d is a better fit for the data. \n",
    "#The adjusted R^2 score is higher than part b and c and has the lowest AIC as well. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
